{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sprint11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZOL7-FxQ7yQ"
      },
      "source": [
        "# Simple Convolutional 1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDpmxw24bLIw"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etvKJ8MYEVR7"
      },
      "source": [
        "class Initializer:\n",
        "    def __init__(self, sigma=0.02):\n",
        "        self.sigma = sigma\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "      \"\"\"\n",
        "      Weight initialization\n",
        "      Parameters\n",
        "      ----------\n",
        "      n_nodes1 : int\n",
        "        Number of nodes in the previous layer\n",
        "      n_nodes2 : int\n",
        "        Number of nodes in the later layer\n",
        "      Returns\n",
        "      ----------\n",
        "      W :\n",
        "      \"\"\"\n",
        "      pass\n",
        "    def B(self, n_nodes2):\n",
        "      \"\"\"\n",
        "      Bias initialization\n",
        "      Parameters\n",
        "      ----------\n",
        "      n_nodes2 : int\n",
        "        Number of nodes in the later layer\n",
        "      Returns\n",
        "      ----------\n",
        "      B :\n",
        "      \"\"\"\n",
        "      pass\n",
        "class SimpleInitializer(Initializer):\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        return self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "    \n",
        "    def B(self, n_nodes2):\n",
        "        return self.sigma * np.random.randn(n_nodes2)\n",
        "\n",
        "class XavierInitializer(Initializer):\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        return self.sigma * np.random.normal(scale=np.sqrt(1/(n_nodes1+n_nodes2)), size=(n_nodes1, n_nodes2))\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        return self.sigma * np.random.normal(scale=np.sqrt(1/n_nodes2), size=n_nodes2)\n",
        "\n",
        "\n",
        "class HeInitializer(Initializer):\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        return self.sigma * np.random.normal(scale=np.sqrt(2/(n_nodes1+n_nodes2)), size=(n_nodes1, n_nodes2))\n",
        "        # return self.sigma * np.random.normal( size=(n_nodes1, n_nodes2))\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        return self.sigma * np.random.normal(scale=np.sqrt(2/n_nodes2), size=n_nodes2)\n",
        "        # return self.sigma * np.random.normal(size=n_nodes2)"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KQZVcM0ETMF"
      },
      "source": [
        "class Optimizer:\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "    def update(self, layer):\n",
        "        \"\"\"\n",
        "        Update weights and biases for a layer\n",
        "        Parameters\n",
        "        ----------\n",
        "        layer : Instance of the layer before update\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "class SGD(Optimizer):\n",
        "    def update(self, layer):\n",
        "        layer.B -= self.lr*layer.dB\n",
        "        layer.W -= self.lr*layer.dW\n",
        "\n",
        "class AdaGrad(Optimizer):\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "        self.hW = 0\n",
        "        self.hB = 0\n",
        "    def update(self, layer):\n",
        "        self.hW += layer.dW ** 2\n",
        "        self.hB = layer.dB ** 2\n",
        "\n",
        "        layer.W -= self.lr * layer.dW / (np.sqrt(self.hW) + 1e-7)\n",
        "        layer.B -= self.lr * layer.dB / (np.sqrt(self.hB) + 1e-7)"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4x6alLqERqh"
      },
      "source": [
        "class Tanh:\n",
        "    def forward(self, A):\n",
        "      self.A = A\n",
        "      return np.tanh(A)\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "      return dZ * (1 - np.power(np.tanh(self.A),2))\n",
        "\n",
        "class Sigmoid:\n",
        "    def __sigmoid(self, X):\n",
        "      return 1 / ( 1 + np.exp(-X) ) \n",
        "    def forward(self, A):\n",
        "      self.A = A\n",
        "      return self.__sigmoid(A)\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "      return dZ * (1 - self.__sigmoid(self.A)) * self.__sigmoid(self.A)\n",
        "\n",
        "class ReLu:\n",
        "    def forward(self, A):\n",
        "      self.A = A\n",
        "      return np.maximum(A, 0)\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "      return dZ * ((self.A > 0) * 1)\n",
        "\n",
        "class Softmax:\n",
        "    def forward(self, X):\n",
        "      e = np.exp(X)\n",
        "      return e / np.sum(e, axis=1).reshape(-1,1)\n",
        "    \n",
        "    def backward(self, Yhat, Y):\n",
        "      n_batches = Yhat.shape[0]\n",
        "      return (Yhat-Y)/n_batches"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-29z3miixYx"
      },
      "source": [
        "class FC:\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer,\n",
        "                 activation, optimizer, bias=True):\n",
        "        self.n_nodes1 = n_nodes1\n",
        "        self.n_nodes2 = n_nodes2\n",
        "        self.initializer = initializer\n",
        "        self.activation = activation\n",
        "        self.optimizer = optimizer\n",
        "        self.bias = bias\n",
        "        self._init_weights()\n",
        "    \n",
        "    def _init_weights(self):\n",
        "        self.W = self.initializer.W(self.n_nodes1, self.n_nodes2)\n",
        "        self.B = self.initializer.B(self.n_nodes2)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        self.input = X\n",
        "        self.A = np.matmul(X, self.W) + self.B if self.bias else np.matmul(X, self.W)\n",
        "        return self.activation.forward(self.A)\n",
        "\n",
        "    def backward(self, y_pred, y_true=None):\n",
        "        if isinstance(self.activation, Softmax):\n",
        "            dA = self.activation.backward(y_pred, y_true)\n",
        "        else:\n",
        "            dA = self.activation.backward(y_pred)\n",
        "\n",
        "        self.dW = self.input.T @ dA / len(self.input)\n",
        "        self.dB = np.mean(dA, axis=0)\n",
        "        dZ = np.dot(dA, self.W.T)\n",
        "        \n",
        "        self.optimizer.update(self)\n",
        "        return dZ"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUUnGe8abfj1"
      },
      "source": [
        "class GetMiniBatch:\n",
        "    def __init__(self, X, y, batch_size=20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LQd-b-fRnzG"
      },
      "source": [
        "# **Problem 1** Creating a one-dimensional convolutional layer class that limits the number of channels to one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEXkUoiklG96"
      },
      "source": [
        "def forward(X, W, B):\n",
        "    filter_size = len(X) - len(W) + 1\n",
        "\n",
        "    a = np.zeros(shape=(filter_size,))\n",
        "\n",
        "    for i in range(filter_size):\n",
        "        a[i] = np.sum(X[i:i + len(W)] * W) + B\n",
        "    return a\n",
        "\n",
        "def backward(X, W, dA):\n",
        "    if dA.ndim == 1:\n",
        "        dB = np.array([np.sum(dA)])\n",
        "    else:\n",
        "        dB = np.sum(dA, axis=1)\n",
        "\n",
        "    dW = np.zeros(len(W))\n",
        "    for i in range(len(W)):\n",
        "        dW[i] = np.sum(X[i:i+len(dA)] * dA)\n",
        "\n",
        "    zero = np.zeros(len(dA) - 1)\n",
        "    padding_W = np.concatenate([zero, W, zero], axis=0)\n",
        "    dX = np.zeros(len(X))\n",
        "    for i in range(len(X)):\n",
        "        dX[i] = np.sum(padding_W[i:i+len(dA)] * dA[::-1])\n",
        "\n",
        "    return dB, dW, dX"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqrqmO3moO1u"
      },
      "source": [
        "# **Problem 2:** Output size calculation after one-dimensional convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-SMJfqIoN5K"
      },
      "source": [
        "def output_shape(n_in, filter_size, padding=0, stride=1):\n",
        "    shape = (n_in + 2*padding - filter_size) / stride + 1\n",
        "    return int(shape)"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0fVVqyG9uur"
      },
      "source": [
        "# **Problem 3:** Experiment of one-dimensional convolutional layer with small array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpEQ_yROExru"
      },
      "source": [
        "x = np.array([1,2,3,4])\n",
        "w = np.array([3,5,7])\n",
        "b = np.array([1])\n",
        "delta_a = np.array([10, 20])"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfXHnc2kpeyJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d6bea8-0bc5-4439-a09f-2896554486fd"
      },
      "source": [
        "output_shape(4, 3, 0, 1)"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdWngioWD_vh",
        "outputId": "3f3b90f5-ec3d-4e6e-f039-f4d66ccf2495"
      },
      "source": [
        "print('forward pass:', forward(x, w, b))\n",
        "print('backward pass:', backward(x, w, delta_a))"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward pass: [35. 50.]\n",
            "backward pass: (array([30]), array([ 50.,  80., 110.]), array([ 30., 110., 170., 140.]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6D5NKqBGoky"
      },
      "source": [
        "# **Problem 4:** Creating a one-dimensional convolutional layer class that does not limit the number of channels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQdCdButJtQY"
      },
      "source": [
        "# Shape (2, 4): (number of input channels, number of features)\n",
        "x = np.array([[1, 2, 3, 4],\n",
        "              [2, 3, 4, 5]])\n",
        "\n",
        "# Shape: (number of output channels, number of input channels, filter_size)\n",
        "w = np.ones((3, 2, 3))\n",
        "\n",
        "# Shape: (number of output channels)\n",
        "b = np.array([1, 2, 3])"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLb9XFduK7RP"
      },
      "source": [
        "def forward_with_channel(X, W, B):\n",
        "    out_feature_size = output_shape(X.shape[1], W.shape[2])\n",
        "    A = np.zeros((W.shape[0], out_feature_size))\n",
        "\n",
        "    for out_channel in range(W.shape[0]):\n",
        "        for in_channel in range(W.shape[1]):\n",
        "            for i in range(out_feature_size):\n",
        "                A[out_channel, i] += np.sum(X[in_channel, i:i + W.shape[2]] * W[out_channel, in_channel, :])\n",
        "\n",
        "    A += B[:, np.newaxis]\n",
        "    return A\n",
        "\n",
        "def backward_with_channel(X, W, B, dA):\n",
        "    if dA.ndim == 1:\n",
        "        dB = np.array([np.sum(dA)])\n",
        "    else:\n",
        "        dB = np.sum(dA, axis=1)\n",
        "\n",
        "    dW = np.zeros(W.shape)\n",
        "    for out_channel in range(W.shape[0]):\n",
        "        for in_channel in range(W.shape[1]):\n",
        "            for fs in range(W.shape[2]):\n",
        "                dW[out_channel, in_channel, fs] += np.sum(X[in_channel, fs:fs + dA.shape[1]] * dA[out_channel])\n",
        "    \n",
        "    dX = np.zeros(X.shape)\n",
        "    for out_channel in range(W.shape[0]):\n",
        "        for in_channel in range(W.shape[1]):\n",
        "            for fs in range(W.shape[2]):\n",
        "                for m in range(dA.shape[1]):\n",
        "                    dX[in_channel, fs + m] += W[out_channel, in_channel, fs] * dA[out_channel, m]\n",
        "    \n",
        "    return dW, dB, dX"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY2_0KYaTHfg",
        "outputId": "a23c788a-884d-4368-b2cc-2e11a86af3e7"
      },
      "source": [
        "forward_with_channel(x, w, b)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16., 22.],\n",
              "       [17., 23.],\n",
              "       [18., 24.]])"
            ]
          },
          "metadata": {},
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XxXFEjMOfVT"
      },
      "source": [
        "#**Problem 5:** (Advanced task) Implementing padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rvvoy6rj-XMj"
      },
      "source": [
        "def pad(X, padding=0):\n",
        "    return np.pad(X, padding, \"constant\")"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q03R-CkCk_kF",
        "outputId": "9698d32a-a9b1-4790-e479-422a248486c7"
      },
      "source": [
        "pad([1, 2, 3, 4, 5], 1)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WiCxaHSlEeY",
        "outputId": "ea3c8a5f-cccc-4071-fd98-3865b17038fb"
      },
      "source": [
        "a = [[1, 2, 3],\n",
        "     [4, 5, 6],\n",
        "     [7, 8, 9]]\n",
        "pad(a, 3)"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 2, 3, 0, 0, 0],\n",
              "       [0, 0, 0, 4, 5, 6, 0, 0, 0],\n",
              "       [0, 0, 0, 7, 8, 9, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17g0ETCfoeYV"
      },
      "source": [
        "# **Problem 6:** (Advanced task) Response to mini batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jg-UqqEbg2l"
      },
      "source": [
        "class SimpleInitializerConv1d:\n",
        "    def __init__(self, sigma=0.02, seed=None):\n",
        "        self.sigma = sigma\n",
        "        self.seed = seed\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    def W(self, *shape):\n",
        "        W = self.sigma * np.random.randn(*shape)\n",
        "        return W\n",
        "\n",
        "    def B(self, *shape):\n",
        "        B = self.sigma * np.random.randn(*shape)\n",
        "        return B"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igH6_gC3Q3cr"
      },
      "source": [
        "class SimpleConv1d:\n",
        "    def __init__(self, out_channel, in_channel, filter_size,\n",
        "                 padding=0, stride=1, initializer=None,\n",
        "                 optimizer=None, activation=None):\n",
        "        self.out_channel = out_channel\n",
        "        self.in_channel = in_channel\n",
        "        self.filter_size = filter_size\n",
        "        self.padding = padding\n",
        "        self.stride = stride\n",
        "\n",
        "        self.initializer = initializer\n",
        "        self.optimizer = optimizer\n",
        "        self.activation = activation\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        self.W = self.initializer.W(self.out_channel, self.in_channel, self.filter_size)\n",
        "        self.B = self.initializer.B(self.out_channel)\n",
        "    \n",
        "    def _output_shape(self, n_features):\n",
        "        return int((n_features + 2 * self.padding - self.filter_size) / self.stride + 1)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        self.input = X\n",
        "        self.N, self.in_channel, n_features = X.shape\n",
        "        self.OUT = self._output_shape(n_features)\n",
        "\n",
        "        self.A = np.zeros((self.N, self.out_channel, self.OUT))\n",
        "        for n in range(self.N):\n",
        "            for out_channel in range(self.out_channel):\n",
        "                for in_channel in range(self.in_channel):\n",
        "                    pad_X = np.pad(self.input[n, in_channel], self.padding)\n",
        "                    for m in range(self.OUT):\n",
        "                        stride_m = m * self.stride\n",
        "                        self.A[n, out_channel, m] += np.sum(pad_X[stride_m:stride_m + self.filter_size] * self.W[out_channel, in_channel, :])\n",
        "\n",
        "        self.A += self.B[:, None]\n",
        "        self.output = self.activation.forward(self.A)\n",
        "        return self.output\n",
        "    \n",
        "    def backward(self, d):\n",
        "        dA = self.activation.backward(d)\n",
        "\n",
        "        # Gradient B\n",
        "        self.dB = np.mean(np.sum(dA, axis=2), axis=0)\n",
        "\n",
        "        # Gradient W, X\n",
        "        self.dW = np.zeros(self.W.shape)\n",
        "        dZ = np.zeros((*self.input.shape[:-1], self.input.shape[-1] + 2 * self.padding))\n",
        "\n",
        "        for n in range(self.N):\n",
        "            for out_channel in range(self.out_channel):\n",
        "                for in_channel in range(self.in_channel):\n",
        "                    pad_X = np.pad(self.input[n, in_channel], self.padding)\n",
        "                    for fs in range(self.filter_size):\n",
        "                        for m in range(self.OUT):\n",
        "                            stride_m = m * self.stride\n",
        "                            self.dW[out_channel, in_channel, fs] += pad_X[fs + stride_m] * dA[n, out_channel, m]\n",
        "                            dZ[n, in_channel, fs + stride_m] += self.W[out_channel, in_channel, fs] * dA[n, out_channel, m]\n",
        "        \n",
        "        if self.padding > 0:\n",
        "            dZ = dZ[:, :, self.padding:-self.padding]\n",
        "\n",
        "        self.optimizer.update(self)\n",
        "        return dZ"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8goL5uQrbBT"
      },
      "source": [
        "# **Problem 7:** (Advance assignment) Arbitrary number of strides"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7lDNI-AlIoK"
      },
      "source": [
        "def forward_with_strides(X, W, B, padding=0, stride=1):\n",
        "    out_feature_size = output_shape(X.shape[1], W.shape[2], padding, stride)\n",
        "    A = np.zeros((W.shape[0], out_feature_size))\n",
        "\n",
        "    for out_channel in range(W.shape[0]):\n",
        "        for in_channel in range(W.shape[1]):\n",
        "            for i in range(0, out_feature_size):\n",
        "                X_padded = pad(X[in_channel], padding)\n",
        "                idx = i * stride\n",
        "                A[out_channel, i] += np.sum(X_padded[idx:idx + W.shape[2]] * W[out_channel, in_channel, :])\n",
        "\n",
        "    A += B[:, None]\n",
        "    return A\n",
        "\n",
        "def backward_with_strides(X, W, B, dA, padding=0, stride=1):\n",
        "    if dA.ndim == 1:\n",
        "        dB = np.array([np.sum(dA)])\n",
        "    else:\n",
        "        dB = np.sum(dA, axis=1)\n",
        "\n",
        "    dW = np.zeros(W.shape)\n",
        "    dX = np.zeros((*X.shape[:-1], X.shape[-1] + 2*padding))\n",
        "    for out_channel in range(W.shape[0]):\n",
        "        for in_channel in range(W.shape[1]):\n",
        "            for fs in range(W.shape[2]):\n",
        "                for i in range(dA.shape[1]):\n",
        "                    X_padded = pad(X[in_channel], padding)\n",
        "                    dW[out_channel, in_channel, fs] += X_padded[fs + i*stride] * dA[out_channel, i]\n",
        "                    dX[in_channel, fs + i*stride] += W[out_channel, in_channel, fs] * dA[out_channel, i]\n",
        "\n",
        "    if padding > 0:\n",
        "        dX = dX[:, padding:-padding]\n",
        "    return dW, dB, dX"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhSgC7a-rOT9"
      },
      "source": [
        "x = np.array([[1, 2, 3, 4],\n",
        "              [2, 3, 4, 5]])\n",
        "\n",
        "w = np.ones((3, 2, 3))\n",
        "\n",
        "b = np.array([1, 2, 3])\n",
        "\n",
        "dA = np.array([[9, 11, 10],\n",
        "               [32, 35, 30],\n",
        "               [52, 56, 50]])"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z58Fo07PsBAL",
        "outputId": "010d3596-4e92-4ca7-f835-232f5809fb9b"
      },
      "source": [
        "forward_with_strides(x, w, b, 0, 1)"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16., 22.],\n",
              "       [17., 23.],\n",
              "       [18., 24.]])"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmiBPCYdvLKP",
        "outputId": "ff78d1e4-68b9-4df5-e8ce-5cf5f3fcb7a7"
      },
      "source": [
        "forward_with_strides(x, w, b, 1, 1)"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9., 16., 22., 17.],\n",
              "       [10., 17., 23., 18.],\n",
              "       [11., 18., 24., 19.]])"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rwk8504w3RfJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f37dfad-5518-4ff0-c839-19d995288a88"
      },
      "source": [
        "backward_with_strides(x, w, b, dA, 2, 2)"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[ 41.,  62.,  42.],\n",
              "         [ 62.,  83.,  62.]],\n",
              " \n",
              "        [[125., 190., 137.],\n",
              "         [190., 255., 204.]],\n",
              " \n",
              "        [[206., 312., 220.],\n",
              "         [312., 418., 328.]]]),\n",
              " array([ 30,  97, 158]),\n",
              " array([[195., 102., 192.,  90.],\n",
              "        [195., 102., 192.,  90.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSB8TYTAp1Nw"
      },
      "source": [
        "#**Problem 8** Learning and estimation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOyDXn-A_81K"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def plot_learning_curve(train_loss, val_loss=None):\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    plt.plot(train_loss, label=\"train_loss\", linewidth=5)\n",
        "    if val_loss is not None:\n",
        "        plt.plot(val_loss, label=\"val_loss\", linewidth=5)\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"loss\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xlumGBQBEc7"
      },
      "source": [
        "class ScratchCNNClassifier:\n",
        "    def __init__(self, batch_size=1, epochs=10, CNN=[], FC=[],\n",
        "                 random_state=None, verbose=False):\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.CNN = CNN.copy()\n",
        "        self.FC = FC.copy()\n",
        "        self.random_state = random_state\n",
        "        self.verbose = verbose\n",
        "    \n",
        "    def add(self, layer):\n",
        "        if isinstance(layer, SimpleConv1d):\n",
        "            self.CNN.append(layer)\n",
        "        elif isinstance(layer, FC):\n",
        "            self.FC.append(layer)\n",
        "\n",
        "    def loss_function(self, y_true, y_proba, tol=1e-7):\n",
        "        L = -np.mean(y_true * np.log(y_proba + tol))\n",
        "        return L\n",
        "    \n",
        "    def _feedforward(self, X):\n",
        "        Z = X.reshape(self.batch_size, 1, -1)\n",
        "        for layer in self.CNN:\n",
        "            Z = layer.forward(Z)\n",
        "        self.cnn_out_shape = Z.shape\n",
        "        Z = Z.reshape(self.batch_size, -1)\n",
        "        for layer in self.FC:\n",
        "            Z = layer.forward(Z)\n",
        "        return Z\n",
        "    \n",
        "    def _backpropagation(self, dZ, y_true):\n",
        "        dZ = self.FC[-1].backward(dZ, y_true)\n",
        "        for layer in self.FC[-2::-1]:\n",
        "            dZ = layer.backward(dZ)\n",
        "        dZ = dZ.reshape(self.cnn_out_shape)\n",
        "        for layer in self.CNN[::-1]:\n",
        "            dZ = layer.backward(dZ)\n",
        "        \n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "        for i in range(self.epochs):\n",
        "            mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=self.random_state)\n",
        "            loss = 0\n",
        "            for mini_X, mini_y in mini_batch:\n",
        "                Z = self._feedforward(mini_X)\n",
        "                self._backpropagation(Z, mini_y)\n",
        "                \n",
        "                # Accumulate loss\n",
        "                l = self.loss_function(mini_y, Z)\n",
        "                loss += l\n",
        "                print(\"Loss\", l)\n",
        "\n",
        "            self.train_loss.append(loss / len(mini_batch))\n",
        "            if X_val is not None and y_val is not None:\n",
        "                self.val_loss.append(self.loss_function(y_val, self.predict_proba(X_val)))\n",
        "\n",
        "            if self.verbose:\n",
        "                print(\"Epoch\", i, \"Loss:\", self.train_loss[-1])\n",
        "        return self\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        Z = X[:, np.newaxis, :]\n",
        "        for layer in self.CNN:\n",
        "            Z = layer.forward(Z)\n",
        "        Z = Z.reshape(len(X), -1)\n",
        "        for layer in self.FC:\n",
        "            Z = layer.forward(Z)\n",
        "        return Z\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_proba = self.predict_proba(X)\n",
        "        return np.argmax(y_proba, axis=1)"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_IwOHhqi-1K"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8lHSd7V5ICc"
      },
      "source": [
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0ur_FnS5Mfs"
      },
      "source": [
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_pbjO2X5Sgs",
        "outputId": "38c4bbe9-c595-42f1-e5fd-1ca289764c9d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
        "print(X_train.shape) # (48000, 784)\n",
        "print(X_val.shape) # (12000, 784)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48000, 784)\n",
            "(12000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt2hKJqen81y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c18004a-26e3-4f82-98f9-1d1a3b3e55b1"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_val_one_hot = enc.transform(y_val[:, np.newaxis])\n",
        "print(y_train.shape)\n",
        "print(y_train_one_hot.shape) \n",
        "print(y_train_one_hot.dtype)"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48000,)\n",
            "(48000, 10)\n",
            "float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "933UNuJaACVl"
      },
      "source": [
        "FC1 = FC(15640, 200, initializer=HeInitializer(), activation=ReLu(), optimizer=AdaGrad())\n",
        "FC2 = FC(200, 100, initializer=HeInitializer(), activation=ReLu(), optimizer=AdaGrad())\n",
        "FC3 = FC(100, 10, initializer=SimpleInitializer(), activation=Softmax(), optimizer=AdaGrad())\n",
        "conv1d = SimpleConv1d(out_channel=20, in_channel=1, filter_size=3, padding=0, stride=1,\n",
        "                      initializer=SimpleInitializerConv1d(), optimizer=SGD(0.01), activation=ReLu())\n",
        "model = ScratchCNNClassifier(batch_size=100, epochs=10, verbose=True)\n",
        "model.add(conv1d)\n",
        "model.add(FC1)\n",
        "model.add(FC2)\n",
        "model.add(FC3)"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCnbAdZxC_bD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2f79380-3a38-49ea-f285-1516b353e893"
      },
      "source": [
        "# Only train 1000 first examples because the training time is too long :(\n",
        "model.fit(X_train[:1000], y_train_one_hot[:1000])"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss 0.23021158030661007\n",
            "Loss 0.23067163054012177\n",
            "Loss 0.2301330285056489\n",
            "Loss 0.22971580653426182\n",
            "Loss 0.22981322115662345\n",
            "Loss 0.23016865143021137\n",
            "Loss 0.2304535131613948\n",
            "Loss 0.230321865079178\n",
            "Loss 0.2302835478044615\n",
            "Loss 0.23097652078594003\n",
            "Epoch 0 Loss: 0.2302749365304452\n",
            "Loss 0.22965259704119423\n",
            "Loss 0.22854616031580025\n",
            "Loss 0.22853373294224585\n",
            "Loss 0.23180599817210157\n",
            "Loss 0.22880613534656716\n",
            "Loss 0.23057815921545585\n",
            "Loss 0.22917805219151893\n",
            "Loss 0.22836774895138912\n",
            "Loss 0.2282594198721557\n",
            "Loss 0.22834639658155828\n",
            "Epoch 1 Loss: 0.2292074400629987\n",
            "Loss 0.2259009433400238\n",
            "Loss 0.2281538942294337\n",
            "Loss 0.22811386761517008\n",
            "Loss 0.22741526547336352\n",
            "Loss 0.22477687307208874\n",
            "Loss 0.22532852102559692\n",
            "Loss 0.2234817757083943\n",
            "Loss 0.22341062731611128\n",
            "Loss 0.22547978227726806\n",
            "Loss 0.223182319493964\n",
            "Epoch 2 Loss: 0.2255243869551414\n",
            "Loss 0.22263226475552625\n",
            "Loss 0.22135286744632357\n",
            "Loss 0.21810515736914965\n",
            "Loss 0.22411927914866417\n",
            "Loss 0.22301687574127121\n",
            "Loss 0.21801793593030055\n",
            "Loss 0.21586772224611625\n",
            "Loss 0.21754562260611607\n",
            "Loss 0.21916818934250323\n",
            "Loss 0.21915669919301287\n",
            "Epoch 3 Loss: 0.21989826137789836\n",
            "Loss 0.21590195186100136\n",
            "Loss 0.21474433090614364\n",
            "Loss 0.2131387308722322\n",
            "Loss 0.21374585050672687\n",
            "Loss 0.21381056364947856\n",
            "Loss 0.2111858864286653\n",
            "Loss 0.20537014239070192\n",
            "Loss 0.20801834652430956\n",
            "Loss 0.20702930881606044\n",
            "Loss 0.20183043900190786\n",
            "Epoch 4 Loss: 0.21047755509572275\n",
            "Loss 0.20192533175873673\n",
            "Loss 0.20318129693952275\n",
            "Loss 0.19943821161054961\n",
            "Loss 0.22173064921560923\n",
            "Loss 0.20570364390548723\n",
            "Loss 0.19501214543867004\n",
            "Loss 0.1880128706680873\n",
            "Loss 0.1891663576687809\n",
            "Loss 0.1909667459319721\n",
            "Loss 0.18445062634390547\n",
            "Epoch 5 Loss: 0.19795878794813213\n",
            "Loss 0.18525433915961784\n",
            "Loss 0.18760093014328666\n",
            "Loss 0.18494755776821734\n",
            "Loss 0.18187977979222394\n",
            "Loss 0.189380930862959\n",
            "Loss 0.18218200594562975\n",
            "Loss 0.16791374251484195\n",
            "Loss 0.1812481023072221\n",
            "Loss 0.17298051366471992\n",
            "Loss 0.16636193952580197\n",
            "Epoch 6 Loss: 0.1799749841684521\n",
            "Loss 0.17230813077120832\n",
            "Loss 0.1698402257696422\n",
            "Loss 0.16053278885515573\n",
            "Loss 0.1756952635784974\n",
            "Loss 0.1845106497426999\n",
            "Loss 0.18805702133825372\n",
            "Loss 0.17601241598127382\n",
            "Loss 0.1613178214990732\n",
            "Loss 0.16045846102817654\n",
            "Loss 0.16480733986812746\n",
            "Epoch 7 Loss: 0.1713540118432108\n",
            "Loss 0.15952775879209238\n",
            "Loss 0.1605384497408189\n",
            "Loss 0.14832083619029016\n",
            "Loss 0.16023923516201466\n",
            "Loss 0.14690256968279505\n",
            "Loss 0.15637959452796693\n",
            "Loss 0.1661981792848368\n",
            "Loss 0.16207443180225692\n",
            "Loss 0.1517756055942809\n",
            "Loss 0.14643580640771478\n",
            "Epoch 8 Loss: 0.15583924671850674\n",
            "Loss 0.1529704153547729\n",
            "Loss 0.144625629423144\n",
            "Loss 0.16029310220873236\n",
            "Loss 0.16324810497319267\n",
            "Loss 0.14968592506009148\n",
            "Loss 0.13147501346049784\n",
            "Loss 0.14126674296942485\n",
            "Loss 0.14509899646938418\n",
            "Loss 0.13570425527960706\n",
            "Loss 0.14635420126666351\n",
            "Epoch 9 Loss: 0.14707223864655108\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.ScratchCNNClassifier at 0x7f341cba3a10>"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r6heT1hY0go",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "09aec122-6306-4848-ea6f-852a2d6b0325"
      },
      "source": [
        "plot_learning_curve(model.train_loss)"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}