{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sprint10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToIIjU8uKmGh"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMW1PjuRwgat"
      },
      "source": [
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "Iterator to get a mini-batch\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : The following forms of ndarray, shape (n_samples, n_features)\n",
        "      Training data\n",
        "    y : The following form of ndarray, shape (n_samples, 1)\n",
        "      Correct answer value\n",
        "    batch_size : int\n",
        "      Batch size\n",
        "    seed : int\n",
        "      NumPy random number seed\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]        \n",
        "\n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "        \n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6mErbF8KzU7"
      },
      "source": [
        "class Initializer:\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "      \"\"\"\n",
        "      Weight initialization\n",
        "      Parameters\n",
        "      ----------\n",
        "      n_nodes1 : int\n",
        "        Number of nodes in the previous layer\n",
        "      n_nodes2 : int\n",
        "        Number of nodes in the later layer\n",
        "      Returns\n",
        "      ----------\n",
        "      W :\n",
        "      \"\"\"\n",
        "      pass\n",
        "    def B(self, n_nodes2):\n",
        "      \"\"\"\n",
        "      Bias initialization\n",
        "      Parameters\n",
        "      ----------\n",
        "      n_nodes2 : int\n",
        "        Number of nodes in the later layer\n",
        "      Returns\n",
        "      ----------\n",
        "      B :\n",
        "      \"\"\"\n",
        "      pass\n",
        "class SimpleInitializer(Initializer):\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        return self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "    \n",
        "    def B(self, n_nodes2):\n",
        "        return self.sigma * np.random.randn(n_nodes2)\n",
        "\n",
        "class XavierInitializer(Initializer):\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        return self.sigma * np.random.normal(scale=np.sqrt(1/(n_nodes1+n_nodes2)), size=(n_nodes1, n_nodes2))\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        return self.sigma * np.random.normal(scale=np.sqrt(1/n_nodes2), size=n_nodes2)\n",
        "\n",
        "\n",
        "class HeInitializer(Initializer):\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        return self.sigma * np.random.normal(scale=np.sqrt(2/(n_nodes1+n_nodes2)), size=(n_nodes1, n_nodes2))\n",
        "        # return self.sigma * np.random.normal( size=(n_nodes1, n_nodes2))\n",
        "\n",
        "    def B(self, n_nodes2):\n",
        "        return self.sigma * np.random.normal(scale=np.sqrt(2/n_nodes2), size=n_nodes2)\n",
        "        # return self.sigma * np.random.normal(size=n_nodes2)\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e0vglZjK16y"
      },
      "source": [
        "class Optimizer:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "    def update(self, layer):\n",
        "        \"\"\"\n",
        "        Update weights and biases for a layer\n",
        "        Parameters\n",
        "        ----------\n",
        "        layer : Instance of the layer before update\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "class SGD(Optimizer):\n",
        "    def update(self, layer):\n",
        "        layer.B -= self.lr*layer.dB\n",
        "        layer.W -= self.lr*layer.dW\n",
        "\n",
        "class AdaGrad(Optimizer):\n",
        "    def update(self, layer):\n",
        "        layer.H += np.power(layer.dB,2)\n",
        "        layer.B -= self.lr*(np.sqrt(1/(layer.H + 1e-07)))*layer.dB\n",
        "        layer.W -= self.lr*layer.dW"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCngU84CR6-v"
      },
      "source": [
        "class Tanh:\n",
        "    def forward(self, A):\n",
        "      self.A = A\n",
        "      return np.tanh(A)\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "      return dZ * (1 - np.power(np.tanh(self.A),2))\n",
        "\n",
        "class Sigmoid:\n",
        "    def __sigmoid(self, X):\n",
        "      return 1 / ( 1 + np.exp(-X) ) \n",
        "    def forward(self, A):\n",
        "      self.A = A\n",
        "      return self.__sigmoid(A)\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "      return dZ * (1 - self.__sigmoid(self.A)) * self.__sigmoid(self.A)\n",
        "\n",
        "class ReLu:\n",
        "    def forward(self, A):\n",
        "      self.A = A\n",
        "      return np.maximum(A, 0)\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "      return dZ * ((self.A > 0) * 1)\n",
        "\n",
        "class Softmax:\n",
        "    def forward(self, X):\n",
        "      e = np.exp(X)\n",
        "      return e / np.sum(e, axis=1).reshape(-1,1)\n",
        "    \n",
        "    def backward(self, Yhat, Y):\n",
        "      n_batches = Yhat.shape[0]\n",
        "      return (Yhat-Y)/n_batches"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wusti62IKtoW"
      },
      "source": [
        "class FC:\n",
        "    \"\"\"\n",
        "    Number of nodes Fully connected layer from n_nodes1 to n_nodes2\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_nodes1 : int\n",
        "      Number of nodes in the previous layer\n",
        "    n_nodes2 : int\n",
        "      Number of nodes in the later layer\n",
        "    initializer: instance of initialization method\n",
        "    optimizer: instance of optimization method\n",
        "    \"\"\"\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        # Initialize\n",
        "        # Initialize self.W and self.B using the initializer method\n",
        "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
        "        self.B = initializer.B(n_nodes2)\n",
        "        if type(optimizer) is AdaGrad:\n",
        "          self.H = 0.0\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        forward\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : The following forms of ndarray, shape (batch_size, n_nodes1)\n",
        "            入力\n",
        "        Returns\n",
        "        ----------\n",
        "        A : The following forms of ndarray, shape (batch_size, n_nodes2)\n",
        "            output\n",
        "        \"\"\"\n",
        "        self.Z = X    \n",
        "        A = np.matmul(X, self.W) + self.B\n",
        "        return A\n",
        "\n",
        "    def backward(self, dA):\n",
        "        \"\"\"\n",
        "        Backward\n",
        "        Parameters\n",
        "        ----------\n",
        "        dA : The following forms of ndarray, shape (batch_size, n_nodes2)\n",
        "            Gradient flowing from behind\n",
        "        Returns\n",
        "        ----------\n",
        "        dZ : The following forms of ndarray, shape (batch_size, n_nodes1)\n",
        "            Gradient to flow forward\n",
        "        \"\"\"\n",
        "        self.dB = np.sum(dA, axis=0)\n",
        "        self.dW = np.dot(self.Z.T, dA)\n",
        "        dZ = np.dot(dA, self.W.T)\n",
        "        # update\n",
        "        self = self.optimizer.update(self)\n",
        "        return dZ"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3gGEM_yKIw8"
      },
      "source": [
        "class ScratchDeepNeuralNetrowkClassifier:\n",
        "    def __init__(self, epoch=20, batch_size=20, verbose = True):\n",
        "        self.verbose = verbose\n",
        "        self.epoch = epoch\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def _feed_forward(self, X):\n",
        "        A1 = self.FC1.forward(X)\n",
        "        Z1 = self.activation1.forward(A1)\n",
        "        A2 = self.FC2.forward(Z1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        A3 = self.FC3.forward(Z2)\n",
        "        Z3 = self.activation3.forward(A3)\n",
        "        return Z3\n",
        "\n",
        "    def _backpropagation(self, y_proba, y_true):\n",
        "        dA3 = self.activation3.backward(y_proba, y_true)\n",
        "        dZ2 = self.FC3.backward(dA3)\n",
        "        dA2 = self.activation2.backward(dZ2)\n",
        "        dZ1 = self.FC2.backward(dA2)\n",
        "        dA1 = self.activation1.backward(dZ1)\n",
        "        dZ0 = self.FC1.backward(dA1)\n",
        "\n",
        "    def _loss_function(self, y_proba, y_true):\n",
        "        return -np.mean(y_true*np.log(y_proba + 1e-07))\n",
        "\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        pass\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        return self._feed_forward(X)\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_proba = self.predict_proba(X)\n",
        "        return np.argmax(y_proba, axis=1)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpOZizzO2Wq-"
      },
      "source": [
        "## Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGxmH70Jz_lq"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNQOSMf52liO"
      },
      "source": [
        "## Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvxO46bn2Y9O"
      },
      "source": [
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWNMAdjT2ilF"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9_HPmZi2s7t"
      },
      "source": [
        "Preprocess X"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdBf31sX2auK",
        "outputId": "e869b0ad-6a49-4b80-a79e-5d229152a0da"
      },
      "source": [
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print(X_train.max()) # 1.0\n",
        "print(X_train.min()) # 0.0"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkXYfLMs2rMA"
      },
      "source": [
        "Split train - val data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YA1xaDxT2cBQ",
        "outputId": "6af295a3-e53e-45ea-d8dc-5f34d63b8d33"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
        "print(X_train.shape) # (48000, 784)\n",
        "print(X_val.shape) # (12000, 784)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 784)\n",
            "(12000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRb8cRdm2vCE"
      },
      "source": [
        "One-hot encoding Y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgCogTT72deJ",
        "outputId": "a27acef5-7077-4609-a9cc-00f47e62c32f"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_val_one_hot = enc.transform(y_val[:, np.newaxis])\n",
        "print(y_train.shape)\n",
        "print(y_train_one_hot.shape) \n",
        "print(y_train_one_hot.dtype)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000,)\n",
            "(48000, 10)\n",
            "float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZIhqQEV21zC"
      },
      "source": [
        "##**Problem 9**\n",
        "##Learning and estimation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIazIzLT2yyD"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_val = enc.inverse_transform(y_val_one_hot)\n",
        "y_val = y_val.ravel()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXCFTslZJ0F3"
      },
      "source": [
        "##SGD + SimpleInitializer + Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ym5KS4FPxSS"
      },
      "source": [
        "class Model1(ScratchDeepNeuralNetrowkClassifier):\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        self.sigma      = 0.01\n",
        "        self.lr         = 0.01\n",
        "        self.n_features = X.shape[1] # number of features\n",
        "        self.n_nodes1   = 400\n",
        "        self.n_nodes2   = 200\n",
        "        self.n_output   = y.shape[1] # number of output classes (number of nodes in the 3rd layer)\n",
        "\n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "\n",
        "        # Initialize\n",
        "        optimizer = SGD(self.lr)\n",
        "        self.FC1 = FC(self.n_features, self.n_nodes1, SimpleInitializer(self.sigma), optimizer)\n",
        "        self.activation1 = Sigmoid()\n",
        "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, SimpleInitializer(self.sigma), optimizer)\n",
        "        self.activation2 = Sigmoid()\n",
        "        self.FC3 = FC(self.n_nodes2, self.n_output, SimpleInitializer(self.sigma), optimizer)\n",
        "        self.activation3 = Softmax()\n",
        "\n",
        "        for i in range(self.epoch):\n",
        "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size)\n",
        "            for index, (X_batch, y_batch) in enumerate(get_mini_batch):\n",
        "                # Forward\n",
        "                Z3 = self._feed_forward(X_batch)\n",
        "\n",
        "                # Backprop\n",
        "                self._backpropagation(Z3, y_batch)\n",
        "\n",
        "            self.train_loss.append(self._loss_function(self.predict_proba(X), y))\n",
        "            if X_val is not None and y_val is not None:\n",
        "                self.val_loss.append(self._loss_function(self.predict_proba(X_val), y_val))\n",
        "\n",
        "            if self.verbose:\n",
        "                print(f'epoch: {i}, loss: {self.train_loss[-1]}')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmxCZaYXKuzS",
        "outputId": "5a0aa4fe-39e9-40b4-f48a-8aaf92dabd9c"
      },
      "source": [
        "scratch_model_1 = Model1()\n",
        "scratch_model_1.fit(X_train, y_train_one_hot, X_val, y_val_one_hot)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, loss: 0.23103246471570454\n",
            "epoch: 1, loss: 0.23095209851645065\n",
            "epoch: 2, loss: 0.23085663141794022\n",
            "epoch: 3, loss: 0.2307233878422672\n",
            "epoch: 4, loss: 0.23048247737548921\n",
            "epoch: 5, loss: 0.2298169973698218\n",
            "epoch: 6, loss: 0.22598526363889443\n",
            "epoch: 7, loss: 0.19431720843375377\n",
            "epoch: 8, loss: 0.1562846435117943\n",
            "epoch: 9, loss: 0.12578877017756293\n",
            "epoch: 10, loss: 0.1070477496767722\n",
            "epoch: 11, loss: 0.08661182165086774\n",
            "epoch: 12, loss: 0.07801993674737993\n",
            "epoch: 13, loss: 0.07336625139136578\n",
            "epoch: 14, loss: 0.06976712408023678\n",
            "epoch: 15, loss: 0.06627609995603422\n",
            "epoch: 16, loss: 0.06257061841373147\n",
            "epoch: 17, loss: 0.05885497856905892\n",
            "epoch: 18, loss: 0.055595737898015814\n",
            "epoch: 19, loss: 0.05296986087107281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIT-3YKrKyZF"
      },
      "source": [
        "y_pred = scratch_model_1.predict(X_val)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icpJakp4R3_3",
        "outputId": "6e440de3-06c4-4e5a-b61d-79c5bc78904b"
      },
      "source": [
        "accuracy_score(y_pred, y_val)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8395"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXzy7GPdJ_70"
      },
      "source": [
        "##SGD + HeInitializer + ReLu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynLjzK29BJoC"
      },
      "source": [
        "class Model2(ScratchDeepNeuralNetrowkClassifier):\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        self.sigma      = 0.01\n",
        "        self.lr         = 0.01\n",
        "        self.n_features = X.shape[1] # number of features\n",
        "        self.n_nodes1   = 400\n",
        "        self.n_nodes2   = 200\n",
        "        self.n_output   = y.shape[1] # number of output classes (number of nodes in the 3rd layer)\n",
        "\n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "\n",
        "        # Initialize\n",
        "        optimizer = SGD(self.lr)\n",
        "        self.FC1 = FC(self.n_features, self.n_nodes1, HeInitializer(self.sigma), optimizer)\n",
        "        self.activation1 = ReLu()\n",
        "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, HeInitializer(self.sigma), optimizer)\n",
        "        self.activation2 = ReLu()\n",
        "        self.FC3 = FC(self.n_nodes2, self.n_output, HeInitializer(self.sigma), optimizer)\n",
        "        self.activation3 = Softmax()\n",
        "\n",
        "        for i in range(self.epoch):\n",
        "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size)\n",
        "            for index, (X_batch, y_batch) in enumerate(get_mini_batch):\n",
        "                # Forward\n",
        "                Z3 = self._feed_forward(X_batch)\n",
        "\n",
        "                # Backprop\n",
        "                self._backpropagation(Z3, y_batch)\n",
        "\n",
        "            self.train_loss.append(self._loss_function(self.predict_proba(X), y))\n",
        "            if X_val is not None and y_val is not None:\n",
        "                self.val_loss.append(self._loss_function(self.predict_proba(X_val), y_val))\n",
        "\n",
        "            if self.verbose:\n",
        "                print(f'epoch: {i}, loss: {self.train_loss[-1]}')"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXhBYkWWz8Lc",
        "outputId": "638ecd38-2b46-438c-afbf-d2fdd50da0b4"
      },
      "source": [
        "scratch_model_2 = Model2()\n",
        "scratch_model_2.fit(X_train, y_train_one_hot, X_val, y_val_one_hot)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, loss: 0.23012620954951873\n",
            "epoch: 1, loss: 0.23012714675179516\n",
            "epoch: 2, loss: 0.23012732204391398\n",
            "epoch: 3, loss: 0.23012728820433534\n",
            "epoch: 4, loss: 0.23012719780082685\n",
            "epoch: 5, loss: 0.23012702740271535\n",
            "epoch: 6, loss: 0.23012665205688196\n",
            "epoch: 7, loss: 0.2301255529914926\n",
            "epoch: 8, loss: 0.23012033065981172\n",
            "epoch: 9, loss: 0.23004024526639363\n",
            "epoch: 10, loss: 0.1865439105585739\n",
            "epoch: 11, loss: 0.14674698648975348\n",
            "epoch: 12, loss: 0.12998666921571683\n",
            "epoch: 13, loss: 0.11469202122107941\n",
            "epoch: 14, loss: 0.06817801718048722\n",
            "epoch: 15, loss: 0.04720774886683682\n",
            "epoch: 16, loss: 0.037807099736954904\n",
            "epoch: 17, loss: 0.03048494604667859\n",
            "epoch: 18, loss: 0.025246575653172357\n",
            "epoch: 19, loss: 0.021406559205862017\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxPzJreE_ciL"
      },
      "source": [
        "y_pred = scratch_model_2.predict(X_val)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ye6IStKK970",
        "outputId": "5fe36cfa-e567-44ac-eccd-96bc7bddb351"
      },
      "source": [
        "accuracy_score(y_pred, y_val)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9329166666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trtlQvKeKFtw"
      },
      "source": [
        "##SGD + XavierInitializer + Tanh"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU5OLz3oKMIW"
      },
      "source": [
        "class Model3(ScratchDeepNeuralNetrowkClassifier):\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        self.sigma      = 0.01\n",
        "        self.lr         = 0.01\n",
        "        self.n_features = X.shape[1] # number of features\n",
        "        self.n_nodes1   = 400\n",
        "        self.n_nodes2   = 200\n",
        "        self.n_output   = y.shape[1] # number of output classes (number of nodes in the 3rd layer)\n",
        "\n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "\n",
        "        # Initialize\n",
        "        optimizer = SGD(self.lr)\n",
        "        self.FC1 = FC(self.n_features, self.n_nodes1, XavierInitializer(self.sigma), optimizer)\n",
        "        self.activation1 = Tanh()\n",
        "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, XavierInitializer(self.sigma), optimizer)\n",
        "        self.activation2 = Tanh()\n",
        "        self.FC3 = FC(self.n_nodes2, self.n_output, XavierInitializer(self.sigma), optimizer)\n",
        "        self.activation3 = Softmax()\n",
        "\n",
        "        for i in range(self.epoch):\n",
        "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size)\n",
        "            for index, (X_batch, y_batch) in enumerate(get_mini_batch):\n",
        "                # Forward\n",
        "                Z3 = self._feed_forward(X_batch)\n",
        "\n",
        "                # Backprop\n",
        "                self._backpropagation(Z3, y_batch)\n",
        "\n",
        "            self.train_loss.append(self._loss_function(self.predict_proba(X), y))\n",
        "            if X_val is not None and y_val is not None:\n",
        "                self.val_loss.append(self._loss_function(self.predict_proba(X_val), y_val))\n",
        "\n",
        "            if self.verbose:\n",
        "                print(f'epoch: {i}, loss: {self.train_loss[-1]}')"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZtci_wyLAHJ",
        "outputId": "0ce96783-820f-4208-b5f7-6c003fcc25a1"
      },
      "source": [
        "scratch_model_3 = Model3()\n",
        "scratch_model_3.fit(X_train, y_train_one_hot, X_val, y_val_one_hot)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, loss: 0.2301262029303276\n",
            "epoch: 1, loss: 0.2301271367793693\n",
            "epoch: 2, loss: 0.2301273087525046\n",
            "epoch: 3, loss: 0.2301272721256824\n",
            "epoch: 4, loss: 0.2301271802079799\n",
            "epoch: 5, loss: 0.2301270130612046\n",
            "epoch: 6, loss: 0.23012666208175805\n",
            "epoch: 7, loss: 0.23012570257492856\n",
            "epoch: 8, loss: 0.23012134278267224\n",
            "epoch: 9, loss: 0.230037044552603\n",
            "epoch: 10, loss: 0.17436836494453914\n",
            "epoch: 11, loss: 0.1597825454640234\n",
            "epoch: 12, loss: 0.11662698389643039\n",
            "epoch: 13, loss: 0.0785070195644493\n",
            "epoch: 14, loss: 0.05351389451465963\n",
            "epoch: 15, loss: 0.0408307089162808\n",
            "epoch: 16, loss: 0.03586514924011039\n",
            "epoch: 17, loss: 0.031843088247308415\n",
            "epoch: 18, loss: 0.029138915162482903\n",
            "epoch: 19, loss: 0.027014474344283026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLXFtMLXLCfv"
      },
      "source": [
        "y_pred = scratch_model_3.predict(X_val)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_ggjQL_KYKk",
        "outputId": "571291ee-0887-4f08-e24e-7c1115b1caa6"
      },
      "source": [
        "accuracy_score(y_pred, y_val)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9154166666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0GRWB4wFWAd"
      },
      "source": [
        "##AdaGrad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvcY0LVh6O7O"
      },
      "source": [
        "class Model4(ScratchDeepNeuralNetrowkClassifier):\n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        self.sigma      = 0.01\n",
        "        self.lr         = 0.01\n",
        "        self.n_features = X.shape[1] # number of features\n",
        "        self.n_nodes1   = 400\n",
        "        self.n_nodes2   = 200\n",
        "        self.n_output   = y.shape[1] # number of output classes (number of nodes in the 3rd layer)\n",
        "\n",
        "        self.train_loss = []\n",
        "        self.val_loss = []\n",
        "\n",
        "        # Initialize\n",
        "        optimizer = AdaGrad(self.lr)\n",
        "        self.FC1 = FC(self.n_features, self.n_nodes1, SimpleInitializer(self.sigma), optimizer)\n",
        "        self.activation1 = ReLu()\n",
        "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, SimpleInitializer(self.sigma), optimizer)\n",
        "        self.activation2 = ReLu()\n",
        "        self.FC3 = FC(self.n_nodes2, self.n_output, SimpleInitializer(self.sigma), optimizer)\n",
        "        self.activation3 = Softmax()\n",
        "\n",
        "        for i in range(self.epoch):\n",
        "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size)\n",
        "            for index, (X_batch, y_batch) in enumerate(get_mini_batch):\n",
        "                # Forward\n",
        "                Z3 = self._feed_forward(X_batch)\n",
        "\n",
        "                # Backprop\n",
        "                self._backpropagation(Z3, y_batch)\n",
        "\n",
        "            self.train_loss.append(self._loss_function(self.predict_proba(X), y))\n",
        "            if X_val is not None and y_val is not None:\n",
        "                self.val_loss.append(self._loss_function(self.predict_proba(X_val), y_val))\n",
        "\n",
        "            if self.verbose:\n",
        "                print(f'epoch: {i}, loss: {self.train_loss[-1]}')"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfecTs0X6RG1",
        "outputId": "6fe0a15e-8f40-442e-dfb8-b57e9e3659a9"
      },
      "source": [
        "scratch_model_4 = Model4()\n",
        "scratch_model_4.fit(X_train, y_train_one_hot, X_val, y_val_one_hot)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, loss: 0.07967009044415699\n",
            "epoch: 1, loss: 0.04255954382292831\n",
            "epoch: 2, loss: 0.03391847934328141\n",
            "epoch: 3, loss: 0.028812227874073126\n",
            "epoch: 4, loss: 0.024678401079650435\n",
            "epoch: 5, loss: 0.021238665029150634\n",
            "epoch: 6, loss: 0.018480415987126887\n",
            "epoch: 7, loss: 0.016255077315290026\n",
            "epoch: 8, loss: 0.014410275508767938\n",
            "epoch: 9, loss: 0.01289089654572756\n",
            "epoch: 10, loss: 0.011592085948214351\n",
            "epoch: 11, loss: 0.01049111519894418\n",
            "epoch: 12, loss: 0.00951967136177652\n",
            "epoch: 13, loss: 0.008674772317749452\n",
            "epoch: 14, loss: 0.007933935855088203\n",
            "epoch: 15, loss: 0.007281655159436782\n",
            "epoch: 16, loss: 0.006695754264384957\n",
            "epoch: 17, loss: 0.006170667294685989\n",
            "epoch: 18, loss: 0.005685922581067491\n",
            "epoch: 19, loss: 0.005255216938358371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5aFNoLW6VFP"
      },
      "source": [
        "y_pred = scratch_model_4.predict(X_val)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TIjQJzj8I3C",
        "outputId": "cf86a583-6ec4-4160-fb01-c4d9df03ce5c"
      },
      "source": [
        "accuracy_score(y_pred, y_val)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9710833333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    }
  ]
}